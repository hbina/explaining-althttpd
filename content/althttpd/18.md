+++
title = "Forbidden"
date = 2021-06-24
+++

Another HTTP response template.
This time its to indicate that the request is forbidden.

```c
/*
** Tell the client that they are not welcomed here.
*/
static void Forbidden(int lineno){
  StartResponse("403 Forbidden");
  nOut += printf(
    "Content-type: text/plain; charset=utf-8\r\n"
    "\r\n"
    "Access denied\n"
  );
  closeConnection = 1;
  MakeLogEntry(0, lineno);
  exit(0);
}
```

# What is Forbidden?

I think its amusing to look at the usage of this function.
It's being used at several places,

```c
hbina.github.io on  master took 4s 
❯ cat ./static/althttpd/althttpd.c | rg --line-number 'Forbidden'
715:static void Forbidden(int lineno){
716:  StartResponse("403 Forbidden");
1764:        Forbidden(230); /* LOG: Referrer is devids.net */
1778:        Forbidden(240);  /* LOG: Illegal content in HOST: parameter */
1838:        Forbidden(250);  /* LOG: Disallowed user agent */
1846:      Forbidden(251);  /* LOG: Disallowed user agent (20190424) */
```

## Forbidden Referer

HTTP headers have a "referer" value when making requests so that the server can know who made the request.
For whatever reason, the author decides to forbid anyone from `devids.net`!

```c
    }else if( strcasecmp(zFieldName,"Referer:")==0 ){
      zReferer = StrDup(zVal);
      if( strstr(zVal, "devids.net/")!=0 ){ zReferer = "devids.net.smut";
        Forbidden(230); /* LOG: Referrer is devids.net */
      }
```

## Forbidden Host

When parsing the `Host` header value, the server will also reply with forbidden if there's illegal content in it.
We will cover what `sanitizeString` is later.

```c
    }else if( strcasecmp(zFieldName,"Host:")==0 ){
      int inSquare = 0;
      char c;
      if( sanitizeString(zVal) ){
        Forbidden(240);  /* LOG: Illegal content in HOST: parameter */
      }
```

## Forbidden Agents

There's also a list of disallowed agents.
I am not sure why half of these are in here...
I guess its just what the author had accumulated after over 20 years of running this program.

```c
if( zAgent ){
    const char *azDisallow[] = {
      "Windows 9",
      "Download Master",
      "Ezooms/",
      "HTTrace",
      "AhrefsBot",
      "MicroMessenger",
      "OPPO A33 Build",
      "SemrushBot",
      "MegaIndex.ru",
      "MJ12bot",
      "Chrome/0.A.B.C",
      "Neevabot/",
      "BLEXBot/",
    };
    size_t ii;
    for(ii=0; ii<sizeof(azDisallow)/sizeof(azDisallow[0]); ii++){
      if( strstr(zAgent,azDisallow[ii])!=0 ){
        Forbidden(250);  /* LOG: Disallowed user agent */
      }
    }
```

## Forbidden Spiders

This one is disabled and its actually quite new!
I am not sure what this is?
I suppose there's a specific misbehaving/malicious website crawler attack the author's server at that time.

```c
#if 0
    /* Spider attack from 2019-04-24 */
    if( strcmp(zAgent,
            "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 "
            "(KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36")==0 ){
      Forbidden(251);  /* LOG: Disallowed user agent (20190424) */
    }
#endif
```

# References

1. [printf](https://man7.org/linux/man-pages/man3/printf.3.html).
2. [exit](https://man7.org/linux/man-pages/man3/exit.3.html).
3. [HTTP Header Referer](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referer).
4. [HTTP Header Host](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Host).
5. [HTTP Header User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent).
